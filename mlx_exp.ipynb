{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/suraj/Documents/projects/deep-researcher/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [01:34<00:00, 13.54s/it]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load(\"Qwen/Qwen3-0.6B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "<think>\n",
      "Okay, the user just said \"hello\". I need to respond appropriately. Since they didn't ask a specific question, I should acknowledge their greeting. Maybe say \"Hello! How can I assist you today?\" to show willingness to help. Keep it friendly and open-ended. Let me make sure there's no confusion with other languages or cultures. Alright, that should work.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? ðŸ˜Š\n",
      "==========\n",
      "Prompt: 9 tokens, 10.022 tokens-per-sec\n",
      "Generation: 91 tokens, 41.944 tokens-per-sec\n",
      "Peak memory: 1.394 GB\n"
     ]
    }
   ],
   "source": [
    "prompt = \"hello\"\n",
    "\n",
    "if tokenizer.chat_template is not None:\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "response = generate(model, tokenizer, prompt=prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"title\": \"The Hobbit\", \"author\": \"J.R.R. Tolkien\", \"year\": 1937}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import os\n",
    "\n",
    "\n",
    "class Book(BaseModel):\n",
    "    title: str\n",
    "    author: str\n",
    "    year: int\n",
    "\n",
    "response = completion(\n",
    "    api_base=\"http://192.168.0.105:1234/v1/\",\n",
    "    api_key=\"fake_key\",\n",
    "    model=\"openai/qwen/qwen3-4b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me about The Hobbit\"}],\n",
    "    response_format=Book,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-t2dyhalkyhg3vi0leg5gqj', created=1748711793, model='qwen/qwen3-4b', object='chat.completion', system_fingerprint='qwen/qwen3-4b', choices=[Choices(finish_reason='stop', index=0, message=Message(content='{\"title\": \"The Hobbit\", \"author\": \"J.R.R. Tolkien\", \"year\": 1937}', role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}))], usage=Usage(completion_tokens=27, prompt_tokens=14, total_tokens=41, completion_tokens_details=None, prompt_tokens_details=None), service_tier=None, stats={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
